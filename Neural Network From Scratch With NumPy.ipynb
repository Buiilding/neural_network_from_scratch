{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61b19cc7",
   "metadata": {},
   "source": [
    "# Building a Neural Network From Scratch with NumPy\n",
    "\n",
    "The goal of this Notebook is to give a hands-on explanation of how Artificial Neural Networks work. I intentionally avoid frameworks like PyTorch or Tensoflow because I wanted to build a better understanding of what Machine Learning models actually are, what Neural Networks actually are, and how they can be made. This Notebook is a collection of information I wish I had when I began this journey. It touches on a little bit of the math, but I don't re-explain the math. I try to link out to more explanatory sources where I think it's valuable. Note: I am not a Machine Learning engineer, nor am I a Data Scientist. I'm a Software Engineer that turned into a political operative (lol). I wrote this for an audience of Software Engineers. Also: I don't have a GPU and I don't want to spend a bunch of money renting one from Amazon. This model can be trained and deployed on a modern CPU in a matter of minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b430ab97",
   "metadata": {},
   "source": [
    "## What We'll Be Doing\n",
    "\n",
    "We're going to build a Neural Network for multi-class classification. All that means is we're going to make a model takes in images and attempts to label them from a set of options. In our case, we're going to create a Neural Network that works with the [MNIST database of handwritten digits](https://webcache.googleusercontent.com/search?q=cache:yann.lecun.com/exdb/mnist/). This database contains 70,000 images of handwritten digits, 0 - 9, and corresponding labels of which digit the handwritten image is. We'll use 60,000 of the images to train our Neural Network, and 10,000 to test its accuracy. I've included the data with this Notebook in the `data/` directory.\n",
    "\n",
    "Neural Networks are particularly handy for image classification tasks. There are many other types of Machine Learning out there, but we won't spend any attention on those."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b93954a",
   "metadata": {},
   "source": [
    "## Background Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66bf518",
   "metadata": {},
   "source": [
    "### Shape of a Neural Network\n",
    "\n",
    "First of all, let's demystify one thing: Neural Networks are just graphs. Just nodes and edges. If you've studying any Computer Science or have a background in Software Engineering, this is probably a familiar conecpet to you. The exact shape of any given Neural Network is dependant on how you build it, but that's something we get to decide. The graph has an input layer that is usually one node per input feature. In our case, a pixel of an image is a feature. Next, there are one or more hidden layers. This is the part that makes this Deep Learning. The presence of one or more hidden layers is the \"deep\" in Deep Learning. There's no standard rule for the size of a hidden layer, or how many you should have. Finally, there's an output layer. Each node in the output layer corresponds to one label. For example, if a possible label to an image is \"cat\" then one node in the output layer represents \"cat\". We're going to make a Neural Network that has a bunch of input layer nodes, a single hidden layer with ten nodes, and an output layer with ten nodes, one for each digit 0 - 9.\n",
    "\n",
    "Each Nueron (node) has a unique Weight and Bias, and each layer has an Activation Function. The Activation Function defines the output of a neuron given its inputs, and does not change. We'll talk more about Activation Functions below. As we create our model, we adjust the Weights and Biases.\n",
    "\n",
    "Here's are drawing of a Neural Network with three input nodes, a hidden layer with four nodes, and an output layer with two nodes. This might be how you would construct a Neural Network that does binary classification: a model that tries to label inputs to one of two options for outputs.\n",
    "\n",
    "| ![Artificial Neural Network](./img/artificial_neural_network.svg)|\n",
    "|:--:|\n",
    "|en:User:Cburnett, [CC BY-SA 3.0](http://creativecommons.org/licenses/by-sa/3.0/), via Wikimedia Commons|\n",
    "\n",
    "If you're looking for more explanation of the structure of Neural Networks, [But what is a Neural Network?](https://www.3blue1brown.com/lessons/neural-networks) by 3Blue1Brown is excellent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d38137a",
   "metadata": {},
   "source": [
    "### How the Neural Network Learns\n",
    "\n",
    "Neural Network start out very stupid. As we'll see, they begin with no more \"intelligence\" than random guessing. Our goal is to iteratively adjust the network's Weights and Biases to make it smarter. We do this in two steps: **Forward Propagation** and **Back Propagation**.\n",
    "\n",
    "#### Forward Propagation\n",
    "\n",
    "Think of this step as showing the Neural Network some input, and asking it to classify it. At the beginning, it's very likely to get it wrong. But, like humans, we need to get things wrong before we know how to get them right. In Forward Propagation, we simply push all our features (pixels) through the Neural Network and ask, \"what did you see?\" The output is all the answers to that question.\n",
    "\n",
    "#### Back Propagation\n",
    "\n",
    "Think of this step as showing the Neural Network how right or wrong its answers were. We take all its answers to, \"what did you see?\" and come up with a measure of how wrong they were. We'll see below that we can assign a numeric value to the accuracy of its answer. From that numerica value, we can work backwards on all the neurons (nodes in the graph) to tell it, \"you were X wrong, and this specific neuron contributed to Y amount of that error; adjust this neuron's Weights and Biases by Z amount and try again.\"\n",
    "\n",
    "3Blue1Brown has another excellent video on the conecepts of Back Propagation: [What is backpropagation really doing?](https://www.3blue1brown.com/lessons/backpropagation)\n",
    "\n",
    "#### Training\n",
    "\n",
    "And that's it! Our Neural Network learns by repeatedly making guesses, seeing how wrong it was, and adjusting its Weights and Biases. We repeat this over and over until it is good at the task! This is a lot like how people learn. Show a small child pictures of various farm animals over and over and ask them to name the animals. At first they're very bad at it, and over time they get very good at it. There's a lot of research out there that our artifical Neural Network is structured and operates like human brain neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b585aa",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "\n",
    "Gradient Descent is the most math-y piece of all this. Again, 3Blue1Brown has a great video: [Gradient descent, how neural networks learn](https://www.3blue1brown.com/lessons/gradient-descent). This is the piece that is most choose-your-own-adventure of how much you want to actually understand. I recommend diving in at least a little bit.\n",
    "\n",
    "Imagine being at a point graph and you wanted to find which steps to take to get to the minimum value. If you've taken any calculus before, you know that you can take the slope at the current point to tell you which way to go, and by how much. If you do this over and over, with small steps, you will approach a local minimum. That's a 1-dimensional gradient descent. Our plan is to work with lots of repeated steps to get to a minumum of our \"cost\" function â€” the function telling us how bad our predictions are.\n",
    "\n",
    "| ![Gradient Descent](./img/GradientDescentGradientStep.svg)|\n",
    "|:--:|\n",
    "|Reducing Loss: Gradient Descent, [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/), via [Google Developers](https://developers.google.com/machine-learning/crash-course/reducing-loss/gradient-descent)|\n",
    "\n",
    "You can do this in two and three domensions as well. In fact, you can do it in as many dimensions as you need, which is very handy, because we're going to be working in a lot of dimensions.\n",
    "\n",
    "| ![Gradient Descent](./img/GradientDescent.gif)|\n",
    "|:--:|\n",
    "|[CC0 1.0 Universal (CC0 1.0) Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/deed.en), via Wikimedia Commons|\n",
    "\n",
    "Ultimately, we keep moving downward in our many-dimensional \"cost\" function to find a minimum value. The lower the cost, the better the prediction.\n",
    "\n",
    "TKTK - you need to say more here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cf0516",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "As stated, we're going to build and train a fully functioning Neural Network using only **NumPy**. That said, I'm also going to install **matplotlib** just so that we can visualize some of the work as we go. It's completely unnecessary to use matplotlib. Both of these libraries are set in `requirements.txt`.\n",
    "\n",
    "It's also worth pointing out that I'm developing this in Python 3.10. Other versions of Python 3 probably work, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d95761d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib==3.5.* in /Users/hodgesmr/.virtualenvs/neural_network/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (3.5.2)\n",
      "Requirement already satisfied: numpy==1.23.* in /Users/hodgesmr/.virtualenvs/neural_network/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (1.23.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/hodgesmr/.virtualenvs/neural_network/lib/python3.10/site-packages (from matplotlib==3.5.*->-r requirements.txt (line 1)) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/hodgesmr/.virtualenvs/neural_network/lib/python3.10/site-packages (from matplotlib==3.5.*->-r requirements.txt (line 1)) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/hodgesmr/.virtualenvs/neural_network/lib/python3.10/site-packages (from matplotlib==3.5.*->-r requirements.txt (line 1)) (4.33.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/hodgesmr/.virtualenvs/neural_network/lib/python3.10/site-packages (from matplotlib==3.5.*->-r requirements.txt (line 1)) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/hodgesmr/.virtualenvs/neural_network/lib/python3.10/site-packages (from matplotlib==3.5.*->-r requirements.txt (line 1)) (9.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/hodgesmr/.virtualenvs/neural_network/lib/python3.10/site-packages (from matplotlib==3.5.*->-r requirements.txt (line 1)) (1.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/hodgesmr/.virtualenvs/neural_network/lib/python3.10/site-packages (from matplotlib==3.5.*->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/hodgesmr/.virtualenvs/neural_network/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib==3.5.*->-r requirements.txt (line 1)) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4d686c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288d6894",
   "metadata": {},
   "source": [
    "## Our Data\n",
    "\n",
    "As mentioned, we're going to be working with the MNIST database of handwritten digits. This is a very handy beginer's data set because it's done a lot of the upfront work for us. First of all, the data is normalized: all images are 28 x 28 and grayscale. The standard size is particularly helpful because we're going to need that to set up the input layer of our Neural Network. It other situations, you'd have to crop or squash or letterbox your images to make them a standard size. This is mostly boilerplate, but some details of the file format that you may wish to know:\n",
    "\n",
    "* The images are encoded in the [IDX file format](https://www.fon.hum.uva.nl/praat/manual/IDX_file_format.html), which looks for the presence of some magic numbers\n",
    "* There's a [documented structure](http://yann.lecun.com/exdb/mnist/) to this data set, but that website is often behind HTTP basid auth because people like to script against it; here's a [Google cache](https://webcache.googleusercontent.com/search?q=cache:yann.lecun.com/exdb/mnist/)\n",
    "* In summary, the image data are 28 x 28 images in a single gzip'd binary file with 0 - 255 pixel values and we're going to read them in as floats and divide by 255 to get values 0 - 1\n",
    "\n",
    "Here, we can read in all the training data. We want to structure it into a matrix where each pixel is a row, and each image is a column. This gives us a matrix with 784 rows and 60,000 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f92d65fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "DATA_DIR = \"./data/\"\n",
    "TEST_IMAGE_FILE_PATH = f\"{DATA_DIR}/t10k-images-idx3-ubyte.gz\"\n",
    "TEST_LABEL_FILE_PATH = f\"{DATA_DIR}/t10k-labels-idx1-ubyte.gz\"\n",
    "TRAINING_IMAGE_FILE_PATH = f\"{DATA_DIR}/train-images-idx3-ubyte.gz\"\n",
    "TRAINING_LABEL_FILE_PATH = f\"{DATA_DIR}/train-labels-idx1-ubyte.gz\"\n",
    "\n",
    "def load_images_and_labels(image_file_path, label_file_path):\n",
    "    labels = None\n",
    "    image_data = None\n",
    "\n",
    "    with gzip.open(label_file_path, \"r\") as label_file:\n",
    "        # Verify magic number\n",
    "        magic_number_bytes = label_file.read(4)\n",
    "        magic_number = int.from_bytes(magic_number_bytes, byteorder=\"big\", signed=False)\n",
    "        assert magic_number == 2049\n",
    "\n",
    "        # Read header telling us the number of labels\n",
    "        number_of_labels_bytes = label_file.read(4)\n",
    "        number_of_labels = int.from_bytes(\n",
    "            number_of_labels_bytes, byteorder=\"big\", signed=False\n",
    "        )\n",
    "\n",
    "        buffer = label_file.read(number_of_labels)\n",
    "        labels = np.frombuffer(buffer, dtype=np.uint8)\n",
    "\n",
    "        with gzip.open(image_file_path, \"r\") as image_file:\n",
    "            # Verify magic number\n",
    "            magic_number_bytes = image_file.read(4)\n",
    "            magic_number = int.from_bytes(\n",
    "                magic_number_bytes, byteorder=\"big\", signed=False\n",
    "            )\n",
    "            assert magic_number == 2051\n",
    "\n",
    "            # Read header telling us the number of images\n",
    "            # And check that it matches the number of labels\n",
    "            number_of_images_bytes = image_file.read(4)\n",
    "            number_of_images = int.from_bytes(\n",
    "                number_of_images_bytes, byteorder=\"big\", signed=False\n",
    "            )\n",
    "            assert number_of_images == number_of_labels\n",
    "\n",
    "            # Read the image height header\n",
    "            image_height_bytes = image_file.read(4)\n",
    "            image_height = int.from_bytes(\n",
    "                image_height_bytes, byteorder=\"big\", signed=False\n",
    "            )\n",
    "\n",
    "            # Read the image width header\n",
    "            image_width_bytes = image_file.read(4)\n",
    "            image_width = int.from_bytes(\n",
    "                image_width_bytes, byteorder=\"big\", signed=False\n",
    "            )\n",
    "\n",
    "            # read in the image data\n",
    "            buffer = image_file.read(image_width * image_height * number_of_images)\n",
    "            image_data = np.frombuffer(buffer, dtype=np.uint8).astype(np.float64) / 255\n",
    "\n",
    "            # Reshape it to a matrix such that each column is the pixels of the image\n",
    "            # So, we end up with a matrix with `image_width*image_height` rows and `number_of_images` colums\n",
    "            image_data = image_data.reshape(\n",
    "                number_of_images, image_width * image_height\n",
    "            ).T\n",
    "\n",
    "    return image_data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42f3bff",
   "metadata": {},
   "source": [
    "And show the first image and label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a4764e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_image_data, training_labels = load_images_and_labels(TRAINING_IMAGE_FILE_PATH, TRAINING_LABEL_FILE_PATH)\n",
    "first_image_data = training_image_data[:, 0].reshape((28, 28))  # All the rows in the first column, reshaped back to 28 x 28\n",
    "first_image_label = training_labels[0]\n",
    "\n",
    "print(f'Label: {first_image_label}')\n",
    "plt.imshow(first_image_data, cmap='gray_r', vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a544bb7",
   "metadata": {},
   "source": [
    "## An Untrained Network\n",
    "\n",
    "### Initializing Weights and Biases\n",
    "\n",
    "The first step in creating our Neural Network is to build out Forward Propagation. Since our Neural Network will have an input layer, one hidden layer, and an output layer, we'll need:\n",
    "* a set of Weights and Biases on the input layer\n",
    "* an activation function on the input layer\n",
    "* a set of Weights and Biases on the hidden layer\n",
    "* an activation function on the hidden layer\n",
    "\n",
    "As mentioned, the Weights and Biases are variable and are determined in the model's training process. But our model needs to start somewhere. There are a variety of strategies for initializing Weights and Biases. You could initialize to random values, but we're going to use the [He method](https://towardsdatascience.com/coding-neural-network-parameters-initialization-f7c2d770e874) to initialize random Weights, and the [common recommendation of Biases initialized to zero](https://cs231n.github.io/neural-networks-2/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "896d9690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights_1 is the matrix of Weights between our input nodes and the first hidden layer\n",
    "# it has the shape num_labels x image_size\n",
    "#\n",
    "# biases_1 is the matrix of Biases between our input nodes and the first hidden layer\n",
    "# it has the shape num_labels x 1\n",
    "#\n",
    "# weights_2 is the matrix of Weights between our hidden layer and our output layer\n",
    "# it has the shape num_labels x num_labels\n",
    "#\n",
    "# biases_2 is the matrix of biases between our hidden layer and our output layer\n",
    "# it has the shape num_labels x 1\n",
    "def init_params(input_layer_size, hidden_layer_size, output_layer_size):\n",
    "    weights_1 = np.random.randn(\n",
    "        hidden_layer_size,\n",
    "        input_layer_size,\n",
    "    ) * np.sqrt(2 / input_layer_size)\n",
    "    \n",
    "    weights_2 = np.random.randn(\n",
    "        hidden_layer_size,\n",
    "        output_layer_size,\n",
    "    ) * np.sqrt(2 / hidden_layer_size)\n",
    "\n",
    "    biases_1 = np.zeros((hidden_layer_size, 1))\n",
    "    biases_2 = np.zeros((output_layer_size, 1))\n",
    "\n",
    "    return weights_1, biases_1, weights_2, biases_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e96fe25",
   "metadata": {},
   "source": [
    "## Input Layer Activation Function\n",
    "\n",
    "Next we need to select an activation function on our input layer. Common options are [sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function) and [ReLU](https://en.wikipedia.org/wiki/Rectifier_%28neural_networks%29). ReLU is found to be very effective and is a very common choice in computer vision models. Also, it's incredibly simple to implement, so we'll go with that.\n",
    "\n",
    "All it does is take a value as input, and if the value is less than 0, return 0; if the value is greater than 0, return that value. That's it! [Here's a handy post comparing ReLU to other activation functions](https://www.aitude.com/comparison-of-sigmoid-tanh-and-relu-activation-functions/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "527eed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(value):\n",
    "    return np.maximum(value, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111164af",
   "metadata": {},
   "source": [
    "## Hidden Layer Activation Function\n",
    "\n",
    "The last piece we need for our Forward Propagation is an Activation Function on the hidden layer. Remember: this Activation Function is feeding to our output layer, so we need something that generates ten prediction values. A good way to do this is to take our hidden layer and normalize it such that it outputs a normalized \"prediction odds\" to our output layer. Put another way, if the model is 91% sure an input is the number 5, it should activate the 5's output node to 0.91, and the sum of all the other predictions should come to 0.09.\n",
    "\n",
    "What we've just described is called the [Softmax function](https://en.wikipedia.org/wiki/Softmax_function). The mast might look a little strange ([here's a good explainer](https://towardsdatascience.com/softmax-activation-function-explained-a7e1bc3ad60)), but all it's doing is taking in a set of numbers and normalizing them to be 0 - 1, with a sum of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66a326c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(inputs):\n",
    "    exponentiated = np.exp(inputs)\n",
    "    probabilities = exponentiated / np.sum(exponentiated, axis=0)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef22ef9",
   "metadata": {},
   "source": [
    "## Forward Propagation\n",
    "\n",
    "We can now combine our initialized Weights and Biases and our Activation Functions to define Forward Propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33feb5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(weights_1, biases_1, weights_2, biases_2, input_layer):\n",
    "    # First, calculate the unactivated values of the neurons in the first hidden layer\n",
    "    # Dot product weights_1 on input_layer, and then add biases_1\n",
    "    unactivated_hidden_layer = weights_1.dot(input_layer) + biases_1\n",
    "    # Then apply the ReLU activation function, to get our first hidden layer\n",
    "    activated_hidden_layer = relu(unactivated_hidden_layer)\n",
    "\n",
    "    # Next calculate the unactivated values of the neurons in the output layer\n",
    "    # Dot product weights_2 on activated_hidden_layer, and then add biases_2\n",
    "    unactivated_output_layer = weights_2.dot(activated_hidden_layer) + biases_2\n",
    "    # Then apply the softmax activation function, to get our activated output layer\n",
    "    output_layer = softmax(unactivated_output_layer)\n",
    "\n",
    "    return unactivated_hidden_layer, activated_hidden_layer, unactivated_output_layer, output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faef8aa",
   "metadata": {},
   "source": [
    "This is actually all we need to do to have our model make a prediction. If we pass in a matrix of images, it'll give an `output_layer` of predicted labels. But remember, we haven't actually trained it yet, so it'll make **very bad predictions**. The two variables we have, the Weights and Biases, are set to random values. So this thing is going to perform with roughly 10% accuracy (randomly picking one of our ten digits). Let's see that.\n",
    "\n",
    "We can define a measure of accuracy by dividing the number of correct predictions (the labels with the highest value in `output_layer` by total number of predictions.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f060dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)  # return the index of the max value prediction\n",
    "\n",
    "\n",
    "def get_accuracy(predictions, labels):\n",
    "    return np.sum(predictions == labels) / labels.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695e519c",
   "metadata": {},
   "source": [
    "Here's what we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8d57e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 11.39%\n"
     ]
    }
   ],
   "source": [
    "# Set up our Neural Network shape\n",
    "image_size = training_image_data.shape[0]\n",
    "num_labels = len(np.unique(training_labels))\n",
    "hidden_layer_size = num_labels\n",
    "\n",
    "# Initialize our Weights and Biases\n",
    "weights_1, biases_1, weights_2, biases_2 = init_params(image_size, hidden_layer_size, num_labels)\n",
    "\n",
    "( \n",
    "    unactivated_hidden_layer,\n",
    "    activated_hidden_layer,\n",
    "    unactivated_output_layer,\n",
    "    output_layer,\n",
    ") = forward_prop(\n",
    "    weights_1,\n",
    "    biases_1,\n",
    "    weights_2,\n",
    "    biases_2,\n",
    "    training_image_data,\n",
    ")\n",
    "\n",
    "predictions = get_predictions(output_layer)\n",
    "accuracy = get_accuracy(predictions, training_labels)\n",
    "\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('neural_network')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "a4d59240615bdc204a038d83f8a2e00a0f464cd267fddb0bf696d096a2823018"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
